# Module 3: Bellman Equations

In this module, we will see Reinforcement Learning through the lens of Markov Decision Processes. We will also define value functions and 
Q value functions. 

With these ingredients, we will be able to explore the Bellman equations and Bellman optimatily theorems. We will see how one 
can iteratively solve a Reinforcement Learning problem with the help of the Bellman equations and theorems (value iteration and 
Q value iteration). This will be foundational in many Reinforcement Learning algorithms that we will learn later in the course. 

On the practical side, we will determine the value function for a toy policy in the CartPole-v0 environment using value 
iterations. 

# Required reading

This section is for students who are financially disadvantaged and are not able to pay for the full course. You should still be able to learn a lot by going through the reading material listed below and solving the assignments.

The reading materials are a collection of free online resources that cover many of the things that I address in the course videos (though not everything unfortunately). It's best to go through them in the order listed. 

After you are done studying the listed materials, try solving the assignments.

1. [RL Course by David Silver, Lecture 2: Markov Decision Processes](https://www.youtube.com/watch?v=lfHX2hHRMVQ&t)
2. [RL Course by David Silver, Lecture 3: Planning by Dynamic Programming](https://www.youtube.com/watch?v=lfHX2hHRMVQ&t)
