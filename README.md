#  Practical Reinforcement Learning - An online course

1. You will learn all the theory necessary for reasoning about Reinforcement Learning problems, choosing the right algorithm, performance tuning, and debugging. But I will not go into mathematical proofs and instead, point you to appropriate references, in case you fancy such things. The goal is to turn you into a Reinforcement Learning engineer as fast as possible and with 
no-fluff-and-nonsense.

2. My focus is teaching you to apply Reinforcement Learning in real world problems. Whenever we learn a new concept, we will code it up using `Python`, `OpenAI Gym` and `Keras`, so that you become familiar with all the practical details that nobody ever talks about. And believe me, these practical details are extremely hard to find anywhere.

3. You will learn best practices in Reinforcement Learning that will make everything seem 10x easier. I have picked up 
these best practices by implementation tens of different RL algorithms on my own. 

4. You will implement state-of-the-art algorithms in Reinforcement Learning such as PPO and DQN, and develop the knowledge to 
read, understand and implement new research breakthroughs in this field. I want to make sure that you have the tools to take on 
any Reinforcement Learning problem that you may face.

## Course Plan

[Module 1: RL Breakthroughs and Use Cases](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/01_rl_breakthroughs_and_use_cases)

[Module 2: RL basics with `Open AI` Gym](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/02_rl_basics_with_openai_gym)

[Module 3: Bellman Equations](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/03_bellman_equations)

[Module 4: GLIE Monte Carlo](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/04_glie_monte_carlo)

[Module 5: SARSA](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/05_sarsa)

[Module 6: Function approximation (Tile Coding)](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/06_fn_approx_tile_coding)

[Module 7: Function approximation (Fourier Series)](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/07_fn_approx_fourier_series)

[Module 8: Neural Network crash course with `Keras`](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/08_neural_network_crash_course_with_keras)

[Module 9: Function approximation (Neural Network)](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/09_fn_approx_neural_network)

[Module 10: Vanilla Policy Gradient](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/10_vanilla_policy_gradient)

[Module 11: Proximal Policy Approximation](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/11_proximal_policy_optimization)

[Module 12: RL On `Google Cloud`](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/12_rl_on_google_cloud)

[Module 13: Deep Q Network](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/13_deep_q_network)
