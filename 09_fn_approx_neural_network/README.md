# Module 9: Function Approximation (Neural Network)

At the end of this module

1. You will implement your first Deep RL algorithm (Deep SARSA) to solve the `CartPole-v0` environment :tada:
2. You will be able to list the difficulties of using Neural Networks in RL

## Plan

1. :movie_camera: Neural Networks as function approximators
2. :pencil: **Exercise**: *Modify `ModelAndPolicy` for `CartPole-v0` to use a `Keras` model for function approximation.*
3. :pencil: **Exercise**: *Modify the update rule in `ModelAndPolicy` to implement `Keras` model fitting based on
SARSA(0).*
4. :movie_camera: Theoretical limits on convergence for Neural Networks as function approximators

## References

1. [Reinforcement Learning: An Introduction, Second Edition, Section 9.7](https://drive.google.com/file/d/1opPSz5AZ_kVa1uWOdOiveNiBFiEOHjkG/view)
2. [Deep Q-Learning with Keras and Gym (Look at how the MLP is defined in Keras, ignore everything else)](https://keon.io/deep-q-learning/)

## Navigation 

[Next - Module 10: Vanilla Policy Gradient](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/10_vanilla_policy_gradient)

[Previous - Module 8: Neural Network crash course with `Keras`](https://github.com/gutfeeling/practical_rl_for_coders/tree/master/08_neural_network_crash_course_with_keras)

